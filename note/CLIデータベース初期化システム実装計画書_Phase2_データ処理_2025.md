# CLI データベース初期化システム実装計画書 - Phase 2: データ処理

## 📋 概要

### 目的
- データ取得処理の実装（個別取得対応）
- データ補完処理の実装
- データ処理システムのテストと品質保証

### 期間
**2-3日**

### 基本方針
- **個別データ取得**: 各時間足を個別に取得して最大データ量を確保
- **データ品質**: 取得したデータの検証と品質保証
- **エラーハンドリング**: 堅牢なエラー処理と復旧機能

## 🎯 Phase 2 の目標

### 主要成果物
1. **データ取得処理**
   - Yahoo Finance APIからの個別データ取得
   - マルチタイムフレーム対応
   - データ品質検証

2. **データ補完処理**
   - 5分足から1時間足・4時間足への集計
   - 欠損データの埋め合わせ
   - データ連続性の確保

3. **データ処理テストシステム**
   - 単体テストの実装
   - 統合テストの実装
   - パフォーマンステスト

## 📋 詳細タスク

### タスク 2.1: データ取得処理実装

**担当**: 開発者  
**期間**: 1日  
**優先度**: 高

#### 詳細タスク

**2.1.1 ファイル作成**
- [ ] `scripts/cron/data_loader.py`の作成
- [ ] 必要なインポート文の追加
- [ ] 基本クラス構造の定義

**2.1.2 DataLoaderクラスの実装**
- [ ] `__init__()`メソッドの実装
  - [ ] 通貨ペア設定（USD/JPY）
  - [ ] Yahoo Financeクライアント初期化
  - [ ] 個別取得設定の定義
    - [ ] 5分足: 7日分（API制限）
    - [ ] 1時間足: 30日分（API制限）
    - [ ] 4時間足: 60日分（API制限）
    - [ ] 日足: 365日分（API制限）
- [ ] `load_multi_timeframe_data()`メソッドの実装
  - [ ] 各時間足の個別取得
  - [ ] データ品質の検証
  - [ ] データベースへの保存
  - [ ] 取得結果の集計
- [ ] `load_timeframe_data()`メソッドの実装
  - [ ] 特定時間足のデータ取得
  - [ ] 設定情報の取得
  - [ ] Yahoo Finance APIからのデータ取得
  - [ ] データの検証
  - [ ] データベースへの保存
- [ ] `verify_data_quality()`メソッドの実装
  - [ ] データの完全性チェック
  - [ ] データの整合性チェック
  - [ ] 異常値の検出
  - [ ] データ期間の確認
- [ ] `_fetch_and_save_timeframe()`メソッドの実装
  - [ ] Yahoo Finance APIからのデータ取得
  - [ ] データの前処理
  - [ ] データの検証
  - [ ] データベースへの保存
  - [ ] 重複チェックと更新
- [ ] `_validate_timeframe_data()`メソッドの実装
  - [ ] DataFrame形式の検証
  - [ ] 必須カラムの確認
  - [ ] データ型の検証
  - [ ] 欠損値の確認
- [ ] `initialize()`メソッドの実装
  - [ ] セッション初期化
  - [ ] リポジトリ初期化
  - [ ] 接続テスト
- [ ] `cleanup()`メソッドの実装
  - [ ] リソースのクリーンアップ
  - [ ] セッションのクローズ

**2.1.3 個別取得設定の実装**
- [ ] 5分足設定の実装
  - [ ] 期間: 7日分
  - [ ] 間隔: 5分
  - [ ] 最大レコード数: 10000
- [ ] 1時間足設定の実装
  - [ ] 期間: 30日分
  - [ ] 間隔: 1時間
  - [ ] 最大レコード数: 10000
- [ ] 4時間足設定の実装
  - [ ] 期間: 60日分
  - [ ] 間隔: 4時間
  - [ ] 最大レコード数: 10000
- [ ] 日足設定の実装
  - [ ] 期間: 365日分
  - [ ] 間隔: 1日
  - [ ] 最大レコード数: 10000

**2.1.4 データ品質検証の実装**
- [ ] データの完全性チェック
  - [ ] 必須フィールドの確認
  - [ ] データ型の検証
  - [ ] 範囲チェック
- [ ] データの整合性チェック
  - [ ] OHLCVの整合性
  - [ ] タイムスタンプの連続性
  - [ ] 重複データの確認
- [ ] 異常値の検出
  - [ ] 極端な価格変動の検出
  - [ ] 異常な出来高の検出
  - [ ] 不正なデータの検出

**2.1.5 エラーハンドリングの実装**
- [ ] API接続エラーの処理
- [ ] データ取得失敗の処理
- [ ] データベース保存エラーの処理
- [ ] 部分的な失敗の処理
- [ ] 再試行機能の実装

#### 成果物
- `scripts/cron/data_loader.py`
- 単体テストファイル
- データ品質検証機能
- エラーハンドリング機能

#### 受け入れ基準
- [ ] 各時間足の個別取得が正常に動作
- [ ] データ品質の検証が機能する
- [ ] エラー時に適切な処理が実行される
- [ ] 取得したデータが正しく保存される

### タスク 2.2: データ補完処理実装

**担当**: 開発者  
**期間**: 1日  
**優先度**: 高

#### 詳細タスク

**2.2.1 ファイル作成**
- [ ] `scripts/cron/data_completion.py`の作成（hybrid_initialization.pyから改名）
- [ ] 必要なインポート文の追加
- [ ] 基本クラス構造の定義

**2.2.2 DataCompletionProcessorクラスの実装**
- [ ] `__init__()`メソッドの実装
  - [ ] 通貨ペア設定（USD/JPY）
  - [ ] セッション初期化
  - [ ] リポジトリ初期化
- [ ] `complete_1h_data()`メソッドの実装
  - [ ] 5分足データの状況確認
  - [ ] 1時間足データの欠損部分特定
  - [ ] 5分足から1時間足への集計
  - [ ] 補完データの保存
- [ ] `complete_4h_data()`メソッドの実装
  - [ ] 5分足データの状況確認
  - [ ] 4時間足データの欠損部分特定
  - [ ] 5分足から4時間足への集計
  - [ ] 補完データの保存
- [ ] `complete_all_data()`メソッドの実装
  - [ ] 1時間足データの補完
  - [ ] 4時間足データの補完
  - [ ] 補完結果の集計
  - [ ] 結果レポートの生成
- [ ] `verify_completion()`メソッドの実装
  - [ ] 補完結果の確認
  - [ ] データ品質の検証
  - [ ] 統計情報の生成
- [ ] `_aggregate_1h_from_5m()`メソッドの実装
  - [ ] 最新の5分足データを取得
  - [ ] 7日分の5分足データを使用
  - [ ] 1時間単位でグループ化
  - [ ] OHLCVの計算
  - [ ] 1時間足データの作成と保存
- [ ] `_aggregate_4h_from_5m()`メソッドの実装
  - [ ] 最新の5分足データを取得
  - [ ] 30日分の5分足データを使用
  - [ ] 4時間単位でグループ化
  - [ ] OHLCVの計算
  - [ ] 4時間足データの作成と保存
- [ ] `_create_1h_data()`メソッドの実装
  - [ ] データ件数の確認（最低12件必要）
  - [ ] OHLCVの計算
  - [ ] PriceDataModelの作成
  - [ ] データソースの設定
- [ ] `_create_4h_data()`メソッドの実装
  - [ ] データ件数の確認（最低48件必要）
  - [ ] OHLCVの計算
  - [ ] PriceDataModelの作成
  - [ ] データソースの設定
- [ ] `_check_data_status()`メソッドの実装
  - [ ] 各時間足のデータ状況確認
  - [ ] 最新タイムスタンプの取得
  - [ ] データ件数の取得
  - [ ] 統計情報の生成
- [ ] `initialize()`メソッドの実装
  - [ ] セッション初期化
  - [ ] リポジトリ初期化
  - [ ] 接続テスト
- [ ] `cleanup()`メソッドの実装
  - [ ] リソースのクリーンアップ
  - [ ] セッションのクローズ

**2.2.3 5分足から1時間足・4時間足への集計ロジック**
- [ ] 1時間足集計ロジック
  - [ ] 1時間単位でのグループ化
  - [ ] 12件の5分足から1時間足を作成
  - [ ] OHLCVの計算
  - [ ] データソースの設定
- [ ] 4時間足集計ロジック
  - [ ] 4時間単位でのグループ化
  - [ ] 48件の5分足から4時間足を作成
  - [ ] OHLCVの計算
  - [ ] データソースの設定

**2.2.4 OHLCV計算の実装**
- [ ] 始値（Open）の計算
  - [ ] 期間内の最初のデータの始値
- [ ] 高値（High）の計算
  - [ ] 期間内の最大高値
- [ ] 安値（Low）の計算
  - [ ] 期間内の最小安値
- [ ] 終値（Close）の計算
  - [ ] 期間内の最後のデータの終値
- [ ] 出来高（Volume）の計算
  - [ ] 期間内の出来高の合計

**2.2.5 データソース管理の実装**
- [ ] データソースの識別
  - [ ] 直接取得データの識別
  - [ ] 集計データの識別
- [ ] データソースの記録
  - [ ] データソース情報の保存
  - [ ] タイムスタンプの記録
- [ ] 重複チェック
  - [ ] 既存データの確認
  - [ ] 更新処理の実装

#### 成果物
- `scripts/cron/data_completion.py`
- 単体テストファイル
- 集計ロジック機能
- データソース管理機能

#### 受け入れ基準
- [ ] 5分足から1時間足への集計が正常に動作
- [ ] 5分足から4時間足への集計が正常に動作
- [ ] OHLCVが正しく計算される
- [ ] データソースが適切に管理される

### タスク 2.3: データ処理テスト

**担当**: 開発者  
**期間**: 0.5日  
**優先度**: 中

#### 詳細タスク

**2.3.1 データ取得処理の単体テスト**
- [ ] 正常系テスト
  - [ ] 各時間足の個別取得テスト
  - [ ] データ品質検証テスト
  - [ ] データベース保存テスト
- [ ] 異常系テスト
  - [ ] API接続失敗テスト
  - [ ] データ取得失敗テスト
  - [ ] データベース保存失敗テスト
- [ ] 境界値テスト
  - [ ] 最小データ量テスト
  - [ ] 最大データ量テスト
  - [ ] 空データテスト

**2.3.2 データ補完処理の単体テスト**
- [ ] 正常系テスト
  - [ ] 1時間足集計テスト
  - [ ] 4時間足集計テスト
  - [ ] OHLCV計算テスト
- [ ] 異常系テスト
  - [ ] データ不足テスト
  - [ ] 不正データテスト
  - [ ] 集計失敗テスト
- [ ] 境界値テスト
  - [ ] 最小データ件数テスト
  - [ ] 最大データ件数テスト

**2.3.3 統合テスト**
- [ ] データ取得→補完の統合テスト
- [ ] 全時間足の統合テスト
- [ ] エラーケースの統合テスト

**2.3.4 パフォーマンステスト**
- [ ] データ取得の処理時間測定
- [ ] データ補完の処理時間測定
- [ ] メモリ使用量の測定
- [ ] 大量データでのテスト

**2.3.5 データ品質テスト**
- [ ] データの完全性テスト
- [ ] データの整合性テスト
- [ ] 異常値検出テスト
- [ ] データ期間テスト

#### 成果物
- テスト結果レポート
- バグ修正（必要に応じて）
- パフォーマンス改善（必要に応じて）

#### 受け入れ基準
- [ ] 全テストケースが成功
- [ ] データ品質が基準を満たす
- [ ] パフォーマンス要件を満たす
- [ ] テストカバレッジが90%以上

## 🎯 Phase 2 完了基準

### 機能要件
- [ ] データ取得処理が正常に動作
- [ ] データ補完処理が正常に動作
- [ ] 個別取得が正常に動作
- [ ] データ品質検証が機能する

### 品質要件
- [ ] 全テストが成功
- [ ] データ品質が基準を満たす
- [ ] パフォーマンス要件を満たす
- [ ] コードレビュー完了

### 技術要件
- [ ] コードが読みやすく保守しやすい
- [ ] エラー処理が適切に実装されている
- [ ] データ品質が保証されている
- [ ] 拡張性が考慮されている

## 📊 品質保証

### テスト戦略
1. **単体テスト**: 各メソッドの個別テスト
2. **統合テスト**: コンポーネント間の連携テスト
3. **データ品質テスト**: データの正確性と整合性のテスト
4. **パフォーマンステスト**: 処理時間とリソース使用量のテスト

### コードレビュー
- コード品質の評価
- データ処理ロジックの確認
- エラーハンドリングの確認
- パフォーマンスの確認

### 受け入れテスト
- 機能要件の満足度確認
- データ品質要件の満足度確認
- パフォーマンス要件の確認

## 🚨 リスク管理

### 技術的リスク
1. **Yahoo Finance API制限**
   - **対策**: エラーハンドリングと再試行機能
2. **データ取得失敗**
   - **対策**: 部分的な失敗の処理と復旧機能
3. **データ品質問題**
   - **対策**: 包括的なデータ検証機能

### スケジュールリスク
1. **実装遅延**
   - **対策**: バッファ時間の確保
2. **テスト時間不足**
   - **対策**: 優先度の調整

### 品質リスク
1. **データ不整合**
   - **対策**: 包括的なデータ検証
2. **パフォーマンス問題**
   - **対策**: 早期のパフォーマンステスト

## 📈 成功指標

### 技術的指標
- **テストカバレッジ**: 90%以上
- **バグ密度**: 1000行あたり1バグ以下
- **処理時間**: データ取得が5分以内で完了
- **成功率**: 95%以上の成功率

### データ品質指標
- **データ完全性**: 100%のデータ完全性
- **データ整合性**: 100%のデータ整合性
- **異常値検出**: 適切な異常値検出

### 保守性指標
- **コード品質**: 読みやすく保守しやすいコード
- **拡張性**: 新機能追加が容易な設計
- **ドキュメント**: 最新で正確なドキュメント

## 🔄 次のPhaseへの準備

### Phase 3への引き継ぎ事項
- [ ] データ取得処理の動作確認
- [ ] データ補完処理の動作確認
- [ ] データ品質の確認
- [ ] テスト環境の準備

### 技術的負債の確認
- [ ] 未実装機能の確認
- [ ] 改善点の特定
- [ ] 次のPhaseでの対応計画

---

**作成日**: 2025年1月
**バージョン**: 1.0
**作成者**: AI Assistant
**承認者**: ユーザー
